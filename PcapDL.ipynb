{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f37ffa-6808-4bb9-ae68-e472deb34d7f",
   "metadata": {},
   "source": [
    "# Cyber Attack ML classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "d12144af-9e8b-40f2-88cc-23d37c681152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing things \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import OneHotEncoder as ohe\n",
    "le = preprocessing.LabelEncoder()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix , ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "5df06df1-3733-4814-b1a3-54bcd533adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set random seed\n",
    "random.seed(1234567)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "8e2d1cc8-3bec-4eb1-8856-b51bd5f848d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the CIC csvs for HTTP\n",
    "path = \"/Users/belleho/Desktop/Dataset_CIC/HTTP_CIC\" # use your path\n",
    "HTTP_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "http = pd.concat((pd.read_csv(f) for f in HTTP_files))\n",
    "http[\"Label\"] = 0 \n",
    "\n",
    "#import TCP \n",
    "path1 = \"/Users/belleho/Desktop/Dataset_CIC/TCP_CIC\"\n",
    "TCP_files = glob.glob(os.path.join(path1, \"*.csv\"))\n",
    "tcp = pd.concat((pd.read_csv(f) for f in TCP_files))\n",
    "tcp[\"Label\"] = 1\n",
    "\n",
    "#import UDP \n",
    "path2 = \"/Users/belleho/Desktop/Dataset_CIC/UDP_CIC\"\n",
    "UDP_files = glob.glob(os.path.join(path2, \"*.csv\"))\n",
    "udp = pd.concat((pd.read_csv(f) for f in UDP_files))\n",
    "udp[\"Label\"] = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4644c92a-6a02-4ee3-8010-3024883b4701",
   "metadata": {},
   "source": [
    "## Pre-processing data \n",
    "This section is where we clean the data in preparation for the machine learning process. To prepare the data - I have done the following things. \n",
    "- multiply dataset to reduce bias \n",
    "- split to train test data \n",
    "- drop columns that cannot be encoded, such as Timestamp and the IDS\n",
    "- deal with infs, nas, nans\n",
    "- encode Label to one hoe encoding \n",
    "- turn all the variables into float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "5d8a5ad2-34b7-41f0-b359-4f34ada50a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tcp = tcp*3\n",
    "\n",
    "# tcp = pd.concat([tcp]*3)\n",
    "tcp = pd.concat([tcp]*8, ignore_index = True)\n",
    "udp = pd.concat([udp]*10, ignore_index = True)\n",
    "frame = pd.concat([http, tcp, udp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "4b6a9cba-9f46-4390-9e56-a48696e7196d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " http:318289 tcp:356984 udp:81600\n"
     ]
    }
   ],
   "source": [
    "count_0 = 0 \n",
    "count_1 = 0 \n",
    "count_2 = 0 \n",
    "\n",
    "for i in frame[\"Label\"]:\n",
    "    if i == 0:\n",
    "        count_0+=1\n",
    "    if i == 1:\n",
    "        count_1+=1\n",
    "    if i == 2:\n",
    "        count_2+=1\n",
    "\n",
    "print(\" http:\" + str(count_0) + \" tcp:\"+ str(count_1) + \" udp:\" + str(count_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "a66a4766-4d0d-475d-a6c3-e1455bdb2c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(frame, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "bcab56ce-588a-4205-9451-19d413e8f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train.dropna()\n",
    "train = train.drop(columns = [\"Timestamp\"])\n",
    "train.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
    "train.dropna(inplace=True)\n",
    "train_labels = tf.keras.utils.to_categorical(train[\"Label\"])\n",
    "train = train[train.columns[5:86]]\n",
    "train = train.astype('int64')\n",
    "train = train.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "ad4d510a-e722-4f5d-9f30-0e8e8ec11191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>Fwd Pkt Len Mean</th>\n",
       "      <th>Fwd Pkt Len Std</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79152</th>\n",
       "      <td>17.0</td>\n",
       "      <td>31266489.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15574034.0</td>\n",
       "      <td>1775215.0</td>\n",
       "      <td>16829301.0</td>\n",
       "      <td>14318767.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7300</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2352148.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31799</th>\n",
       "      <td>6.0</td>\n",
       "      <td>24657055.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66369.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66369.0</td>\n",
       "      <td>66369.0</td>\n",
       "      <td>24500567.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24500567.0</td>\n",
       "      <td>24500567.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209733</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1449113.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10252.0</td>\n",
       "      <td>763.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1139.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>17.0</td>\n",
       "      <td>58434571.0</td>\n",
       "      <td>3546.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113472.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1756697.0</td>\n",
       "      <td>1498692.0</td>\n",
       "      <td>3222139.0</td>\n",
       "      <td>226832.0</td>\n",
       "      <td>17703005.0</td>\n",
       "      <td>8653348.0</td>\n",
       "      <td>27392890.0</td>\n",
       "      <td>10746183.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29515</th>\n",
       "      <td>6.0</td>\n",
       "      <td>231897.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>17.0</td>\n",
       "      <td>57773147.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3627.0</td>\n",
       "      <td>5126.0</td>\n",
       "      <td>7252.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28882412.0</td>\n",
       "      <td>369813.0</td>\n",
       "      <td>29143910.0</td>\n",
       "      <td>28620915.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1022925.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198858</th>\n",
       "      <td>6.0</td>\n",
       "      <td>22784877.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>121132.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>1398.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13563564.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13563564.0</td>\n",
       "      <td>13563564.0</td>\n",
       "      <td>5278786.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5278786.0</td>\n",
       "      <td>5278786.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297115</th>\n",
       "      <td>6.0</td>\n",
       "      <td>75772237.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>151732.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1296.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8658920.0</td>\n",
       "      <td>9382794.0</td>\n",
       "      <td>19463935.0</td>\n",
       "      <td>2566792.0</td>\n",
       "      <td>7024542.0</td>\n",
       "      <td>1639174.0</td>\n",
       "      <td>8917224.0</td>\n",
       "      <td>6063729.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>605388 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Protocol  Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  TotLen Fwd Pkts  \\\n",
       "79152       17.0     31266489.0          11.0           1.0              0.0   \n",
       "7300         6.0      2352148.0           2.0           5.0             17.0   \n",
       "31799        6.0     24657055.0           1.0           3.0              0.0   \n",
       "209733       6.0      1449113.0           9.0           5.0          10252.0   \n",
       "957         17.0     58434571.0        3546.0           1.0         113472.0   \n",
       "...          ...            ...           ...           ...              ...   \n",
       "29515        6.0       231897.0           2.0           1.0              0.0   \n",
       "1425        17.0     57773147.0          40.0           1.0              0.0   \n",
       "153          6.0      1022925.0           1.0           3.0              0.0   \n",
       "198858       6.0     22784877.0         110.0          60.0         121132.0   \n",
       "297115       6.0     75772237.0         117.0          32.0         151732.0   \n",
       "\n",
       "        TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  Fwd Pkt Len Mean  \\\n",
       "79152               0.0              0.0              0.0               0.0   \n",
       "7300              384.0             17.0              0.0               8.0   \n",
       "31799               0.0              0.0              0.0               0.0   \n",
       "209733            763.0           1460.0              0.0            1139.0   \n",
       "957                32.0             32.0             32.0              32.0   \n",
       "...                 ...              ...              ...               ...   \n",
       "29515               0.0              0.0              0.0               0.0   \n",
       "1425                0.0              0.0              0.0               0.0   \n",
       "153                 0.0              0.0              0.0               0.0   \n",
       "198858            315.0           1398.0              0.0            1101.0   \n",
       "297115              0.0           1444.0              0.0            1296.0   \n",
       "\n",
       "        Fwd Pkt Len Std  ...  Fwd Seg Size Min  Active Mean  Active Std  \\\n",
       "79152               0.0  ...               0.0          3.0         0.0   \n",
       "7300               12.0  ...               0.0          0.0         0.0   \n",
       "31799               0.0  ...               0.0      66369.0         0.0   \n",
       "209733            636.0  ...               0.0          0.0         0.0   \n",
       "957                 0.0  ...               0.0    1756697.0   1498692.0   \n",
       "...                 ...  ...               ...          ...         ...   \n",
       "29515               0.0  ...               0.0          0.0         0.0   \n",
       "1425                0.0  ...               0.0       3627.0      5126.0   \n",
       "153                 0.0  ...               0.0          0.0         0.0   \n",
       "198858            409.0  ...               0.0   13563564.0         0.0   \n",
       "297115            433.0  ...               0.0    8658920.0   9382794.0   \n",
       "\n",
       "        Active Max  Active Min   Idle Mean   Idle Std    Idle Max    Idle Min  \\\n",
       "79152          3.0         3.0  15574034.0  1775215.0  16829301.0  14318767.0   \n",
       "7300           0.0         0.0         0.0        0.0         0.0         0.0   \n",
       "31799      66369.0     66369.0  24500567.0        0.0  24500567.0  24500567.0   \n",
       "209733         0.0         0.0         0.0        0.0         0.0         0.0   \n",
       "957      3222139.0    226832.0  17703005.0  8653348.0  27392890.0  10746183.0   \n",
       "...            ...         ...         ...        ...         ...         ...   \n",
       "29515          0.0         0.0         0.0        0.0         0.0         0.0   \n",
       "1425        7252.0         2.0  28882412.0   369813.0  29143910.0  28620915.0   \n",
       "153            0.0         0.0         0.0        0.0         0.0         0.0   \n",
       "198858  13563564.0  13563564.0   5278786.0        0.0   5278786.0   5278786.0   \n",
       "297115  19463935.0   2566792.0   7024542.0  1639174.0   8917224.0   6063729.0   \n",
       "\n",
       "        Label  \n",
       "79152     2.0  \n",
       "7300      0.0  \n",
       "31799     0.0  \n",
       "209733    1.0  \n",
       "957       2.0  \n",
       "...       ...  \n",
       "29515     0.0  \n",
       "1425      2.0  \n",
       "153       0.0  \n",
       "198858    1.0  \n",
       "297115    1.0  \n",
       "\n",
       "[605388 rows x 78 columns]"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "5b3ab609-cb26-44db-b035-2f476b278b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = test.drop(columns = [\"Timestamp\"])\n",
    "test.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
    "# test = test.dropna()\n",
    "test.dropna(inplace=True)\n",
    "test_labels = tf.keras.utils.to_categorical(test[\"Label\"])\n",
    "test = test[test.columns[5:87]]\n",
    "test = test.astype('int64')\n",
    "test = test.astype('float64') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0012f6c-fa25-4dd0-90c9-59254e87018b",
   "metadata": {},
   "source": [
    "# Finding inf, nas, and null values \n",
    "for colname in clean_train.columns:\n",
    "    c = np.isinf(clean_train[colname]).values.sum()\n",
    "    print(str(colname) + \" contains \" + str(c) + \" infinite values\")\n",
    "\n",
    "- Flow Byts/s contains 6 infinite values\n",
    "- Flow Pkts/s contains 22 infinite values\n",
    "\n",
    "for colname in clean_train.columns:\n",
    "    c = np.isnan(clean_train[colname]).values.sum()\n",
    "    print(str(colname) + \" contains \" + str(c) + \" NA values\")\n",
    "\n",
    "- Flow Byts/s contains 16 NA values\n",
    "\n",
    "for colname in clean_train.columns:\n",
    "    c = clean_train[colname].isnull().sum()\n",
    "    print(str(colname) + \" contains \" + str(c) + \" null values\")\n",
    "\n",
    "- Flow Byts/s contains 16 null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34a621a-24ea-45cd-a112-fe01ad2dd3fa",
   "metadata": {},
   "source": [
    "\n",
    "### neural network building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "b13138d4-278e-42e0-877a-85494cb7d61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dnn = train.iloc[: ,0:77]\n",
    "# X_train_dnn = train[relevant_l]\n",
    "y_train_dnn = train_labels\n",
    "X_train_dnn = X_train_dnn.to_numpy()\n",
    "\n",
    "X_test_dnn = test.iloc[:,0:77]\n",
    "# X_test_dnn = test[relevant_l] \n",
    "y_test_dnn = test_labels\n",
    "X_test_dnn = X_test_dnn.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "ac111ccb-d52a-481f-8492-e474d4640b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(65, input_shape = (77,), activation = \"relu\", name = \"input\"))\n",
    "model.add(tf.keras.layers.Dense(200, activation = \"relu\", name = \"h2\"))\n",
    "model.add(tf.keras.layers.Dense(150, activation = \"relu\", name = \"h3\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h4\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h5\"))\n",
    "model.add(tf.keras.layers.Dense(200, activation = \"relu\", name = \"h6\"))\n",
    "model.add(tf.keras.layers.Dense(150, activation = \"relu\", name = \"h7\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h8\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h9\"))\n",
    "model.add(tf.keras.layers.Dense(200, activation = \"relu\", name = \"h10\"))\n",
    "model.add(tf.keras.layers.Dense(150, activation = \"relu\", name = \"h11\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h12\"))\n",
    "model.add(tf.keras.layers.Dense(150, activation = \"relu\", name = \"h13\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h14\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h15\"))\n",
    "# model.add(tf.keras.layers.Dense(200, activation = \"relu\", name = \"h16\"))\n",
    "# model.add(tf.keras.layers.Dense(150, activation = \"relu\", name = \"h17\"))\n",
    "# model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h18\"))\n",
    "# model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h19\"))\n",
    "# model.add(tf.keras.layers.Dense(200, activation = \"relu\", name = \"h20\"))\n",
    "# model.add(tf.keras.layers.Dense(150, activation = \"relu\", name = \"h21\"))\n",
    "# model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h22\"))\n",
    "# model.add(tf.keras.layers.Dense(200, activation = \"relu\", name = \"h23\"))\n",
    "# model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h24\"))\n",
    "# model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h25\"))\n",
    "# model.add(tf.keras.layers.Dense(200, activation = \"relu\", name = \"h26\"))\n",
    "# model.add(tf.keras.layers.Dense(150, activation = \"relu\", name = \"h27\"))\n",
    "# model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h28\"))\n",
    "# model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h29\"))\n",
    "# model.add(tf.keras.layers.Dense(200, activation = \"relu\", name = \"h30\"))\n",
    "# model.add(tf.keras.layers.Dense(150, activation = \"relu\", name = \"h31\"))\n",
    "# model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h32\"))\n",
    "# model.add(tf.keras.layers.Dense(150, activation = \"relu\", name = \"h33\"))\n",
    "# model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h34\"))\n",
    "# model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h35\"))\n",
    "# model.add(tf.keras.layers.Dense(200, activation = \"relu\", name = \"h36\"))\n",
    "# model.add(tf.keras.layers.Dense(150, activation = \"relu\", name = \"h37\"))\n",
    "# model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h38\"))\n",
    "# model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h39\"))\n",
    "# model.add(tf.keras.layers.Dense(200, activation = \"relu\", name = \"h40\"))\n",
    "# model.add(tf.keras.layers.Dense(150, activation = \"relu\", name = \"h41\"))\n",
    "# model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h42\"))\n",
    "# model.add(tf.keras.layers.Dense(150, activation = \"relu\", name = \"h43\"))\n",
    "# model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h44\"))\n",
    "# model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h45\"))\n",
    "# model.add(tf.keras.layers.Dense(200, activation = \"relu\", name = \"h46\"))\n",
    "# model.add(tf.keras.layers.Dense(150, activation = \"relu\", name = \"h47\"))\n",
    "# model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h48\"))\n",
    "# model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"h49\"))\n",
    "# model.add(tf.keras.layers.Dense(200, activation = \"relu\", name = \"h50\"))\n",
    "model.add(tf.keras.layers.Dense(3, activation=\"softmax\", name = \"output\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "8e5756c5-c4f7-4738-aa38-45850d7b9e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt =  tf.keras.optimizers.Adam(learning_rate = 0.0003)\n",
    "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "5ea2528d-c3ab-488e-a654-2855425378f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1211/1211 [==============================] - 8s 6ms/step - loss: 51.2427 - accuracy: 0.8066\n",
      "Epoch 2/30\n",
      "1211/1211 [==============================] - 7s 6ms/step - loss: 7.9913 - accuracy: 0.8175\n",
      "Epoch 3/30\n",
      "1211/1211 [==============================] - 7s 6ms/step - loss: 1.9878 - accuracy: 0.8743\n",
      "Epoch 4/30\n",
      "1211/1211 [==============================] - 7s 6ms/step - loss: 5.5468 - accuracy: 0.8572\n",
      "Epoch 5/30\n",
      "1211/1211 [==============================] - 7s 6ms/step - loss: 1.4767 - accuracy: 0.8637\n",
      "Epoch 6/30\n",
      "1211/1211 [==============================] - 7s 6ms/step - loss: 0.7888 - accuracy: 0.8756\n",
      "Epoch 7/30\n",
      "1211/1211 [==============================] - 7s 6ms/step - loss: 0.5689 - accuracy: 0.8879\n",
      "Epoch 8/30\n",
      "1211/1211 [==============================] - 7s 6ms/step - loss: 1.7040 - accuracy: 0.8597\n",
      "Epoch 9/30\n",
      "1211/1211 [==============================] - 7s 6ms/step - loss: 1.0795 - accuracy: 0.8664\n",
      "Epoch 10/30\n",
      "1211/1211 [==============================] - 7s 6ms/step - loss: 0.3334 - accuracy: 0.8868\n",
      "Epoch 11/30\n",
      "1211/1211 [==============================] - 7s 6ms/step - loss: 0.2502 - accuracy: 0.9025\n",
      "Epoch 12/30\n",
      "1211/1211 [==============================] - 7s 6ms/step - loss: 0.2157 - accuracy: 0.9044\n",
      "Epoch 13/30\n",
      "1211/1211 [==============================] - 7s 6ms/step - loss: 0.9316 - accuracy: 0.8726\n",
      "Epoch 14/30\n",
      "1211/1211 [==============================] - 7s 6ms/step - loss: 0.3427 - accuracy: 0.8857\n",
      "Epoch 15/30\n",
      "1211/1211 [==============================] - 7s 6ms/step - loss: 0.2294 - accuracy: 0.8977\n",
      "Epoch 16/30\n",
      "1211/1211 [==============================] - 7s 6ms/step - loss: 0.2247 - accuracy: 0.9041\n",
      "Epoch 17/30\n",
      "1211/1211 [==============================] - 7s 6ms/step - loss: 0.7326 - accuracy: 0.8905\n",
      "Epoch 18/30\n",
      "1211/1211 [==============================] - 7s 6ms/step - loss: 0.2513 - accuracy: 0.8992\n",
      "Epoch 19/30\n",
      "1211/1211 [==============================] - 7s 6ms/step - loss: 0.2211 - accuracy: 0.9054\n",
      "Epoch 20/30\n",
      "1211/1211 [==============================] - 8s 6ms/step - loss: 0.2826 - accuracy: 0.9014\n",
      "Epoch 21/30\n",
      "1211/1211 [==============================] - 8s 6ms/step - loss: 0.2069 - accuracy: 0.9066\n",
      "Epoch 22/30\n",
      "1211/1211 [==============================] - 8s 6ms/step - loss: 0.3002 - accuracy: 0.9018\n",
      "Epoch 23/30\n",
      "1211/1211 [==============================] - 8s 6ms/step - loss: 0.2208 - accuracy: 0.9037\n",
      "Epoch 24/30\n",
      "1211/1211 [==============================] - 8s 7ms/step - loss: 0.1891 - accuracy: 0.9082\n",
      "Epoch 25/30\n",
      "1211/1211 [==============================] - 8s 6ms/step - loss: 0.2639 - accuracy: 0.9051\n",
      "Epoch 26/30\n",
      "1211/1211 [==============================] - 8s 6ms/step - loss: 0.1886 - accuracy: 0.9098\n",
      "Epoch 27/30\n",
      "1211/1211 [==============================] - 8s 7ms/step - loss: 0.2415 - accuracy: 0.9033\n",
      "Epoch 28/30\n",
      "1211/1211 [==============================] - 8s 6ms/step - loss: 0.1922 - accuracy: 0.9130\n",
      "Epoch 29/30\n",
      "1211/1211 [==============================] - 8s 6ms/step - loss: 0.2382 - accuracy: 0.9051\n",
      "Epoch 30/30\n",
      "1211/1211 [==============================] - 7s 6ms/step - loss: 0.1926 - accuracy: 0.9114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdde9034760>"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size = 500\n",
    "model.fit(X_train_dnn, y_train_dnn, epochs = 30, batch_size = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "623fbe55-966c-491b-89dc-0bf937216d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4730/4730 [==============================] - 5s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test_dnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec878162-70a8-4077-9cd0-f14f2cc74e1b",
   "metadata": {},
   "source": [
    "### Evluate model using:\n",
    "- model.evaluate\n",
    "- confusion matrix\n",
    "- caluclating the sensitivity, specificity, fall out, and false negative rate *for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "b0c03383-4cf9-493b-bff9-b73ca5c22c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4730/4730 [==============================] - 6s 1ms/step - loss: 0.2108 - accuracy: 0.9084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2107970267534256, 0.9084380269050598]"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_dnn, y_test_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "f69f0ed2-c877-4230-b705-951b017d882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(pred,  axis = 1)\n",
    "rounded_labels=np.argmax(y_test_dnn, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "901261b7-62f5-4ab7-a148-ca5f95d40efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(predictions, rounded_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "10273265-6a3b-4a39-b7df-77316a8a28e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "# PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "# NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "# FDR = FP/(TP+FP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "f9e2e825-b87e-4e33-a97b-cffd7e9348f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85176424 0.95292493 0.98349407] [0.96280537 0.87947228 0.99759571] [0.03719463 0.12052772 0.00240429] [0.14823576 0.04707507 0.01650593]\n"
     ]
    }
   ],
   "source": [
    "print(TPR, TNR, FPR, FNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "eec72e68-5b88-4c22-abcb-6bfac59e6b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9084380017310755"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total true positive which is just the accuracy \n",
    "TP.sum()/cm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "1bc54338-0fa9-425d-8b93-e952b33637f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09156199826892455"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total false positive rate which is just 1-accuracy\n",
    "FP.sum()/cm.sum() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
